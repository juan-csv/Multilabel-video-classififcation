{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Info dataset Youtube8M](https://www.kaggle.com/competitions/youtube8m-2019)\n",
    "\n",
    "**frame-level data** <br>\n",
    "You may download to your local computer with instructions here\n",
    "Total size of 1.53TB (Large file warning!)\n",
    "Each video has:\n",
    "\n",
    "- id: unique id for the video, in train set it is a YouTube video id, and in test/validation they are anonymized.\n",
    "- labels: list of labels of that video.\n",
    "- Each frame has rgb: float array of length 1024,\n",
    "- Each frame has audio: float array of length 128\n",
    "- A subset of the validation set videos are provided with segment-level labels. In addition to id, labels and the frame level features described above, they come with\n",
    "- segment_start_times: list of segment start times.\n",
    "- segment_end_times: list of segment end times.\n",
    "- segment_labels: list of segment labels.\n",
    "- segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.\n",
    "\n",
    "Files are in TFRecords format, TensorFlow python readers are available in the github repo.\n",
    "frame-sample.zip - a sample of frame-level data including train00 and train01\n",
    "\n",
    "validate-sample.zip - a sample of validation set data including validate00 and validate01\n",
    "\n",
    "vocabulary.csv - the full data dictionary for label names and their descriptions\n",
    "\n",
    "sample_submission.csv - a sample submission file in the correct format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# add root path\n",
    "PATH_ROOT = Path.cwd()\n",
    "for _ in range(6):\n",
    "    last_files = os.listdir(PATH_ROOT)\n",
    "    if 'src' in last_files:\n",
    "        break\n",
    "    else:\n",
    "        PATH_ROOT = PATH_ROOT.parent\n",
    "sys.path.append(PATH_ROOT.__str__())\n",
    "\n",
    "# Local imports\n",
    "from utils.utils import Map_index2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "only the validation data contains the segment start and times and segment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path data\n",
    "FOLDER_DATA = Path('../data/raw')\n",
    "PATH_VOCABULARY = FOLDER_DATA / 'vocabulary.csv'\n",
    "\n",
    "PATH_TF_TRAIN_00 = (FOLDER_DATA / 'frame' / 'train00.tfrecord').__str__()\n",
    "PATH_TF_TRAIN_01 = (FOLDER_DATA / 'frame' / 'train01.tfrecord').__str__()\n",
    "\n",
    "PATH_TF_VAL_00 = (FOLDER_DATA / 'validate' / 'validate00.tfrecord').__str__()\n",
    "PATH_TF_VAL_01 = (FOLDER_DATA / 'validate' / 'validate01.tfrecord').__str__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in train00.tfrecord:       1015\n",
      "Number of videos in train01.tfrecord:       1041\n",
      "Number of videos in validate00.tfrecord:    16\n",
      "Number of videos in validate01.tfrecord:    16\n"
     ]
    }
   ],
   "source": [
    "get_label_videos = lambda x: [tf.train.Example.FromString(example).features.feature['labels'].int64_list.value for example in tf.python_io.tf_record_iterator(x)]\n",
    "\n",
    "print(f\"Number of videos in train00.tfrecord:       {len(get_label_videos(PATH_TF_TRAIN_00))}\")\n",
    "print(f\"Number of videos in train01.tfrecord:       {len(get_label_videos(PATH_TF_TRAIN_01))}\")\n",
    "print(f\"Number of videos in validate00.tfrecord:    {len(get_label_videos(PATH_TF_VAL_00))}\")\n",
    "print(f\"Number of videos in validate01.tfrecord:    {len(get_label_videos(PATH_TF_VAL_01))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore tfrecord\n",
    "    * labels(list): target, # list of index   \n",
    "    * id(str): video id\n",
    "    * audio_embedding_numpy(array): audio embedding for the first frame, shape: (128,) | min: 0 , max: 255\n",
    "    * rgb_embedding_numpy(array): rgb embedding for the first frame, shape: (1024,) | min: 0 , max: 255\n",
    "    \n",
    "    only for validation data:\n",
    "    * segment_start_times (list): start frame for each segment | len(): number of segments\n",
    "    * segment_end_times (list): end frame for each segment | len(): number of segments\n",
    "    * segment_labels (list): index categorie for each segment | len(): number of segments\n",
    "    * segment_scores (list): value for determining if the segment has the label |  len(): number of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 1st video (../data/raw/validate/validate00.tfrecord):\n",
      "------------------------------------\n",
      "ID VIDEO:               Iv00\n",
      "Number of frames:       190\n",
      "Label index video:      [375, 1036, 1062]\n",
      "Names labels:           ['', 'Laser lighting display', '']\n",
      "Label index segments:   [1036, 1036, 1036, 1036, 1036]\n",
      "Names labels segments:  ['Laser lighting display', 'Laser lighting display', 'Laser lighting display', 'Laser lighting display', 'Laser lighting display']\n",
      "Start frame segmetns:   [145, 110, 135, 155, 70]\n",
      "Ends frame segments:    [150, 115, 140, 160, 75]\n",
      "Scores segments:        [0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "Shape video embedding:  (1024,)\n",
      "Shape adio embedding:   (128,)\n",
      "\n",
      "\n",
      "Get data from 1st video (../data/raw/frame/train00.tfrecord):\n",
      "------------------------------------\n",
      "ID VIDEO:               op00\n",
      "Number of frames:       234\n",
      "Label index video:      [82, 103, 346, 350]\n",
      "Names labels:           ['', '', '', '']\n",
      "Label index segments:   []\n",
      "Names labels segments:  []\n",
      "Start frame segmetns:   []\n",
      "Ends frame segments:    []\n",
      "Scores segments:        []\n",
      "Shape video embedding:  (1024,)\n",
      "Shape adio embedding:   (128,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define function transform bytes 2 array\n",
    "f_bytes2array = lambda x: tf.cast(tf.decode_raw( x.bytes_list.value[0], tf.uint8), tf.float32).numpy()\n",
    "# instance mapping inde 2 labels\n",
    "map_index2label = Map_index2label(PATH_VOCABULARY)\n",
    "\n",
    "def get_info_1st_video(PATH_TF):\n",
    "    \"\"\" Explore tfrecord for the first video\n",
    "    Args:\n",
    "        PATH_TF (str): path of tfrecord\n",
    "\n",
    "    Features:\n",
    "        labels(list): target, # list of index   \n",
    "        id(str): video id\n",
    "        audio_embedding_numpy(array): audio embedding for the first frame, shape: (128,) | min: 0 , max: 255\n",
    "        rgb_embedding_numpy(array): rgb embedding for the first frame, shape: (1024,) | min: 0 , max: 255\n",
    "        \n",
    "        only for validation data:\n",
    "        segment_start_times (list): start frame for each segment | len(): number of segments\n",
    "        segment_end_times (list): end frame for each segment | len(): number of segments\n",
    "        segment_labels (list): index categorie for each segment | len(): number of segments\n",
    "        segment_scores (list): value for determining if the segment has the label |  len(): number of segments\n",
    "    \"\"\"\n",
    "    for example in tf.python_io.tf_record_iterator(PATH_TF):\n",
    "        # get data for the video \n",
    "        tf_example = tf.train.SequenceExample.FromString(example)\n",
    "        \n",
    "        # Only do for validation data\n",
    "        segment_start_times = tf_example.context.feature['segment_start_times'].int64_list.value\n",
    "        segment_end_times = tf_example.context.feature['segment_end_times'].int64_list.value\n",
    "        segment_labels = tf_example.context.feature['segment_labels'].int64_list.value\n",
    "        segment_scores = tf_example.context.feature['segment_scores'].float_list.value\n",
    "        \n",
    "        # get index labels for the video\n",
    "        labels =  tf_example.context.feature['labels'].int64_list.value # list of index\n",
    "\n",
    "        # get id video\n",
    "        id = tf_example.context.feature['id'].bytes_list.value[0].decode(encoding='UTF-8') # str\n",
    "        \n",
    "        # get  audio and rgb embeddings\n",
    "        audio_embedding_bytes =  tf_example.feature_lists.feature_list['audio'].feature\n",
    "        rgb_embedding_bytes =  tf_example.feature_lists.feature_list['rgb'].feature\n",
    "\n",
    "        # get number of frames of video\n",
    "        N_FRAMES_VIDEO = len(audio_embedding_bytes)\n",
    "\n",
    "        # only take the embedding for the first frame\n",
    "        audio_embedding_numpy = f_bytes2array( audio_embedding_bytes[0] ) # shape: (128,) | min: 0 , max: 255\n",
    "        rgb_embedding_numpy = f_bytes2array( rgb_embedding_bytes[0] ) # shape: (1024,) | min: 0 , max: 255\n",
    "        \n",
    "        break # just for exploring the data of the first video\n",
    "\n",
    "    print(f\"Get data from 1st video ({PATH_TF}):\\n------------------------------------\")\n",
    "    print(f\"ID VIDEO:               {id}\")\n",
    "    print(f\"Number of frames:       {N_FRAMES_VIDEO}\")\n",
    "    print(f\"Label index video:      {labels}\")\n",
    "    print(f\"Names labels:           {[map_index2label(index) for index in labels]}\")\n",
    "    print(f\"Label index segments:   {segment_labels}\")\n",
    "    print(f\"Names labels segments:  {[map_index2label(index) for index in segment_labels]}\")\n",
    "    print(f\"Start frame segmetns:   {segment_start_times}\")\n",
    "    print(f\"Ends frame segments:    {segment_end_times}\")\n",
    "    print(f\"Scores segments:        {segment_scores}\")\n",
    "    print(f\"Shape video embedding:  {rgb_embedding_numpy.shape}\")\n",
    "    print(f\"Shape adio embedding:   {audio_embedding_numpy.shape}\")\n",
    "    print('\\n')\n",
    "\n",
    "get_info_1st_video(PATH_TF_VAL_00)\n",
    "get_info_1st_video(PATH_TF_TRAIN_00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>TrainVideoCount</th>\n",
       "      <th>KnowledgeGraphId</th>\n",
       "      <th>Name</th>\n",
       "      <th>WikiUrl</th>\n",
       "      <th>Vertical1</th>\n",
       "      <th>Vertical2</th>\n",
       "      <th>Vertical3</th>\n",
       "      <th>WikiDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>378135</td>\n",
       "      <td>/m/01jddz</td>\n",
       "      <td>Concert</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Concert</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A concert is a live music performance in front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>200813</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>Car</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Car</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A car is a wheeled, self-powered motor vehicle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>181579</td>\n",
       "      <td>/m/026bk</td>\n",
       "      <td>Dance</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dance</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dance is a performance art form consisting of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>135357</td>\n",
       "      <td>/m/02wbm</td>\n",
       "      <td>Food</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Food</td>\n",
       "      <td>Food &amp; Drink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Food is any substance consumed to provide nutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>130835</td>\n",
       "      <td>/m/02vx4</td>\n",
       "      <td>Association football</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Association_foot...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Association football, more commonly known as f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  TrainVideoCount KnowledgeGraphId                  Name  \\\n",
       "0      3           378135        /m/01jddz               Concert   \n",
       "1      7           200813          /m/0k4j                   Car   \n",
       "2      8           181579         /m/026bk                 Dance   \n",
       "3     11           135357         /m/02wbm                  Food   \n",
       "4     12           130835         /m/02vx4  Association football   \n",
       "\n",
       "                                             WikiUrl             Vertical1  \\\n",
       "0              https://en.wikipedia.org/wiki/Concert  Arts & Entertainment   \n",
       "1                  https://en.wikipedia.org/wiki/Car      Autos & Vehicles   \n",
       "2                https://en.wikipedia.org/wiki/Dance  Arts & Entertainment   \n",
       "3                 https://en.wikipedia.org/wiki/Food          Food & Drink   \n",
       "4  https://en.wikipedia.org/wiki/Association_foot...                Sports   \n",
       "\n",
       "  Vertical2 Vertical3                                    WikiDescription  \n",
       "0       NaN       NaN  A concert is a live music performance in front...  \n",
       "1       NaN       NaN  A car is a wheeled, self-powered motor vehicle...  \n",
       "2       NaN       NaN  Dance is a performance art form consisting of ...  \n",
       "3       NaN       NaN  Food is any substance consumed to provide nutr...  \n",
       "4       NaN       NaN  Association football, more commonly known as f...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_df = pd.read_csv(PATH_VOCABULARY)\n",
    "vocabulary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:                      1000\n",
      "Number of classes verticals:            50\n",
      "Number of unique classes + verticals:   1025\n"
     ]
    }
   ],
   "source": [
    "unique_class = vocabulary_df['Index'].unique()\n",
    "unique_vertiacal1 = vocabulary_df['Vertical1'].unique()\n",
    "unique_vertiacal2 = vocabulary_df['Vertical2'].unique()\n",
    "unique_vertiacal3 = vocabulary_df['Vertical3'].unique()\n",
    "\n",
    "classes_verticals = list(unique_vertiacal1) + list(unique_vertiacal2) + list(unique_vertiacal3)\n",
    "total_clases = np.unique(classes_verticals + list(unique_class))\n",
    "N_CLASSES = len( unique_class )\n",
    "N_CLASSES_VERTICAL = len( classes_verticals )\n",
    "print(f\"Number of classes:                      {N_CLASSES}\")\n",
    "print(f\"Number of classes verticals:            {N_CLASSES_VERTICAL}\") # some verticals classes are in CLASESS\n",
    "print(f\"Number of unique classes + verticals:   {len(total_clases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Index             1000 non-null   int64 \n",
      " 1   TrainVideoCount   1000 non-null   int64 \n",
      " 2   KnowledgeGraphId  1000 non-null   object\n",
      " 3   Name              988 non-null    object\n",
      " 4   WikiUrl           988 non-null    object\n",
      " 5   Vertical1         1000 non-null   object\n",
      " 6   Vertical2         153 non-null    object\n",
      " 7   Vertical3         12 non-null     object\n",
      " 8   WikiDescription   988 non-null    object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "vocabulary_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore categories\n",
    "## top 30 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 30 frequent categories:\n",
      " ['Concert', 'Car', 'Association football', 'Food', 'Dance', 'Motorsport', 'Racing', 'Mobile phone', 'Smartphone', 'Cooking', 'Pet', 'Dish (food)', 'Drum kit']\n"
     ]
    }
   ],
   "source": [
    "# Get top n classes\n",
    "from collections import Counter\n",
    "label_mapping = vocabulary_df[['Index', 'Name']].set_index('Index', drop=True).to_dict()['Name'] # dict: key --> index,  values --> name of category | len(): number of categories\n",
    "\n",
    "n = 30\n",
    "labels = get_label_videos(PATH_TF_TRAIN_00)\n",
    "top_n = Counter([item for sublist in labels for item in sublist]).most_common(n) # tuple --> (index, num_samples)\n",
    "top_n_labels = [int(i[0]) for i in top_n]   # list: top n index \n",
    "top_n_label_names = [label_mapping[x] for x in top_n_labels if x in label_mapping] # filter out the labels that aren't in the 1,000 used for this competition\n",
    "\n",
    "print(f\"Most {n} frequent categories:\\n\",top_n_label_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88de8a03d390c9821a705f8812eeaeda47efe29e530260f109fd5a47346b85c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
